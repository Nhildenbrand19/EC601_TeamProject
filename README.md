# EC601_TeamProject

## Sprint 1

Project 1 for EC601

EC 601 Project 1 Arnaud Harmange 09/19/21

The project being discussed in this report is one that was found on Kaggle, a platform designed to propose machine learning projects and provide rewards for submitting functioning solutions. This project centers its focus on a partnership with the National Football League (NFL), as a continuation of an earlier project. Previously, the Kaggle community was provided with a dataset from sensors on football players which allowed the development of a detection algorithm for when a players’ helmet was impacted. Now, the NFL would like the ability to automatically track helmets and the players to whom they belong to on video. In combination with the previous helmet impact detection algorithm, the NFL hopes to use these tools in order to help answer questions related to player safety and the effects of helmet impacts on players over time.

The topic of player safety and both the short and long term effects of severe impacts on players has been a central focus in the NFL and broader impact sports community for several years. As research on Traumatic Brain Injuries (TBIs) and Chronic Traumatic Encephalopathy (CTE) continues to surface and gain traction, many participants in impact sports- such as football- have begun asking questions. The most damning hypothesis is that players involved in football- especially those having played for many years- are at a high risk of having experienced more than one TBI over the course of their long sporting careers. The repeated exposure of the human brain to traumatic injuries appears to significantly increase the likelihood that an individual will develop CTE, Alzheimer’s, dementia, and other neurodegenerative diseases. In an effort to minimize players’ exposure to TBIs, education campaigns have sought to educate players and coaches on the dangers of impacts to the head. Additionally, rule changes and new pad and helmet designs over the years have helped provide better protection for the players. However, even with the significant progress that has been made so far, many competitive players still experience TBIs in the form of concussions, and are therefore still at a higher risk of suffering from various neurodegenerative diseases later in life.

In an effort to help researchers and protect their players, the NFL has provided large datasets including video files from hundreds of games as well as sensor data from players’ helmets. The first step, as previously mentioned, was to interpret the helmet sensor data in order to understand what an impact looked like. Now, the task at hand is to tie the data from the helmet sensors to video of the plays in real time. In order to do this, several approaches have been employed. The first order of business is to gain the ability to track helmets and players directly from the provided video files. Fortunately, many of the participants in the Kaggle challenge have shared their work in the open source spirit. The most promising approach appears to be utilizing a modified version of the Deep SORT algorithm. This algorithm was developed to track objects in video, so it is highly useful in this project. In this case, the approach focuses on modifying the algorithm to track each individual players’ helmet rather than the whole player. This approach splits apart all of the video frames, attempts to find all of the helmets in each of the frames, and then clusters together all of the frames where it thinks it can track the same helmets over a period of time, therefore producing a prediction of sorts for which helmet is where and where it moves over time. Of course, the biggest issue with this approach, as with nearly all deep SORT algorithms, is occlusion. Since players tend to group together and in tight formations, overlapping and disappearing helmets for single or sometimes several video frames is bound to happen. The method of separating the video frames and then clustering those that have the same labeling for the same helmets over time is an attempt to circumvent this issue, so that the frames where helmets cannot be detected or overlap can be more safely ignored.

The second part of the leading approach is to read the number from the players’ jersey in order to determine which helmet sensor data set they represent. This is being done currently only by one contributor utilizing the language detection code available through the EasyOCR open source github page. While this approach appears to work fairly well for a first attempt, there are other potential solutions that have been developed that may better suit this situation. Notably, a publication from the University of Waterloo details a method for the detection of player numbers on jerseys in the game of hockey. While this code is not publicly available, it is sometimes possible to contact the authors of the publication and be granted access to the codebase. Assuming this is a possibility, this computer vision software may work significantly better with almost no tweaking whatsoever, namely due to the fact that it is already developed for use on sports jerseys. Additionally, the fast movement in hockey causing motion blur is not dissimilar to the movements found in football, so this detection and labeling algorithm would likely yield more accurate results overall. The above combined approaches appear to be the most popular and the ones with the most promise. While there are others, they are not notably better in any way than the leading ones, and since the leading ones have garnered the most attention, they have received the most updates. In fact, recently, the Deep SORT implementation for helmet tracking received an update that enabled 5X faster performance than previously possible.

Since the dataset for this project is provided as part for the challenge and is the same for everyone, and the code being shared is all open source and readily available to anyone interested in contributing to the project, it can be assumed that the same results can be achieved. Other than performance differences based on the machine on which the code is being run, all other aspects should be equal. Due to my own relative inexperience with projects of this degree of complexity and my complete inexperience with anything related to machine learning,I have not been able to run this code on the datasets myself in order to determine if the results are in fact exactly reproducible
